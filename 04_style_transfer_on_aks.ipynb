{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Neural Style Transfer on AKS\n",
    "\n",
    "Now that the AKS cluster is up, we need to deploy our __flask app__ and __scoring app__ onto it.\n",
    "\n",
    "To do so, we'll do the following:\n",
    "1. Build our __flask app__ and __scoring app__ push it to Dockerhub\n",
    "2. Create our dot-yaml files for each of these apps (these dot-yaml files will need to have the proper configuration for the pods to use blobfuse to access our blob storage container). We should end up creating: `flask_app_deployment.json` and `scoring_app_deployment.json`\n",
    "3. Use `kubectl` to make these deployments to our AKS cluster\n",
    "4. Expose the __flask app__ REST endpoint so that it can be accessed externally\n",
    "\n",
    "### Kubernetes Deployment\n",
    "In this notebook, we will deploy our __flask app__ and __scoring app__ on the kubernetes cluster. Since the __flask app__ does not require heavy computation, we will deploy it on one node and reserve the remaining nodes for the __scoring app__ as it will perform the parallel computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import set_key, get_key, find_dotenv, load_dotenv\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Scoring App Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scoring_app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile scoring_app/requirements.txt\n",
    "azure==4.0.0\n",
    "torch==0.4.1\n",
    "torchvision==0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scoring_app/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile scoring_app/Dockerfile\n",
    "\n",
    "FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
    "\n",
    "RUN echo \"deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 /\" > /etc/apt/sources.list.d/nvidia-ml.list\n",
    "\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "        build-essential \\\n",
    "        ca-certificates \\\n",
    "        cmake \\\n",
    "        curl \\\n",
    "        git \\\n",
    "        nginx \\\n",
    "        supervisor \\\n",
    "        wget && \\\n",
    "        rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "ENV PYTHON_VERSION=3.6\n",
    "RUN curl -o ~/miniconda.sh -O  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh  && \\\n",
    "    chmod +x ~/miniconda.sh && \\\n",
    "    ~/miniconda.sh -b -p /opt/conda && \\\n",
    "    rm ~/miniconda.sh && \\\n",
    "    /opt/conda/bin/conda create -y --name py$PYTHON_VERSION python=$PYTHON_VERSION && \\\n",
    "    /opt/conda/bin/conda clean -ya\n",
    "ENV PATH /opt/conda/envs/py$PYTHON_VERSION/bin:$PATH\n",
    "ENV LD_LIBRARY_PATH /opt/conda/envs/py$PYTHON_VERSION/lib:/usr/local/cuda/lib64/:$LD_LIBRARY_PATH\n",
    "ENV PYTHONPATH /code/:$PYTHONPATH\n",
    "\n",
    "RUN mkdir /app\n",
    "WORKDIR /app\n",
    "ADD process_images_from_queue.py /app\n",
    "ADD style_transfer.py /app\n",
    "ADD main.py /app\n",
    "ADD util.py /app\n",
    "ADD requirements.txt /app\n",
    "ADD constants.py /app\n",
    "\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "RUN rm /opt/conda/envs/py3.6/lib/python3.6/site-packages/azure/servicebus/constants.py\n",
    "RUN cp constants.py /opt/conda/envs/py3.6/lib/python3.6/site-packages/azure/servicebus/\n",
    "\n",
    "CMD [\"python\", \"main.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  37.89kB\n",
      "Step 1/20 : FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
      " ---> 7e8410ba243b\n",
      "Step 2/20 : RUN echo \"deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 /\" > /etc/apt/sources.list.d/nvidia-ml.list\n",
      " ---> Using cache\n",
      " ---> 2aee8c10151f\n",
      "Step 3/20 : RUN apt-get update && apt-get install -y --no-install-recommends         build-essential         ca-certificates         cmake         curl         git         nginx         supervisor         wget &&         rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> c69b13e821b7\n",
      "Step 4/20 : ENV PYTHON_VERSION=3.6\n",
      " ---> Using cache\n",
      " ---> 9c3490d15c2d\n",
      "Step 5/20 : RUN curl -o ~/miniconda.sh -O  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh  &&     chmod +x ~/miniconda.sh &&     ~/miniconda.sh -b -p /opt/conda &&     rm ~/miniconda.sh &&     /opt/conda/bin/conda create -y --name py$PYTHON_VERSION python=$PYTHON_VERSION &&     /opt/conda/bin/conda clean -ya\n",
      " ---> Using cache\n",
      " ---> 1c03f992fcdc\n",
      "Step 6/20 : ENV PATH /opt/conda/envs/py$PYTHON_VERSION/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> 0657e2c699a2\n",
      "Step 7/20 : ENV LD_LIBRARY_PATH /opt/conda/envs/py$PYTHON_VERSION/lib:/usr/local/cuda/lib64/:$LD_LIBRARY_PATH\n",
      " ---> Using cache\n",
      " ---> 63a9f91c2959\n",
      "Step 8/20 : ENV PYTHONPATH /code/:$PYTHONPATH\n",
      " ---> Using cache\n",
      " ---> 89729243eb37\n",
      "Step 9/20 : RUN mkdir /app\n",
      " ---> Using cache\n",
      " ---> b0591813f73e\n",
      "Step 10/20 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> 9478c90941d9\n",
      "Step 11/20 : ADD process_images_from_queue.py /app\n",
      " ---> Using cache\n",
      " ---> 5cbd91d3b07a\n",
      "Step 12/20 : ADD style_transfer.py /app\n",
      " ---> Using cache\n",
      " ---> 5240c2c86e83\n",
      "Step 13/20 : ADD main.py /app\n",
      " ---> Using cache\n",
      " ---> f06d556d3650\n",
      "Step 14/20 : ADD util.py /app\n",
      " ---> Using cache\n",
      " ---> 6f00348f19a5\n",
      "Step 15/20 : ADD requirements.txt /app\n",
      " ---> Using cache\n",
      " ---> 3376b43dcdf3\n",
      "Step 16/20 : ADD constants.py /app\n",
      " ---> Using cache\n",
      " ---> c3351c2ba415\n",
      "Step 17/20 : RUN pip install --no-cache-dir -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> f58249fc7f3f\n",
      "Step 18/20 : RUN rm /opt/conda/envs/py3.6/lib/python3.6/site-packages/azure/servicebus/constants.py\n",
      " ---> Using cache\n",
      " ---> bb583463b91e\n",
      "Step 19/20 : RUN cp constants.py /opt/conda/envs/py3.6/lib/python3.6/site-packages/azure/servicebus/\n",
      " ---> Using cache\n",
      " ---> a9cc11d9daa2\n",
      "Step 20/20 : CMD [\"python\", \"main.py\"]\n",
      " ---> Using cache\n",
      " ---> a0ad434be761\n",
      "Successfully built a0ad434be761\n",
      "Successfully tagged cambridgesp:latest\n"
     ]
    }
   ],
   "source": [
    "!sudo docker build -t {get_key(env_path, \"SCORING_IMAGE\")} scoring_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag and push docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/aperture/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!sudo docker login --username pjh177787 --password 'Hans&951022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"{}/{}\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"SCORING_IMAGE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker tag {get_key(env_path, \"SCORING_IMAGE\")} {repo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/pjh177787/cambridgesp]\n",
      "\n",
      "\u001b[1Bea68a8e4: Preparing \n",
      "\u001b[1Be9c72ee2: Preparing \n",
      "\u001b[1B4636511d: Preparing \n",
      "\u001b[1B30360c47: Preparing \n",
      "\u001b[1B112a59d2: Preparing \n",
      "\u001b[1Bb59fe06d: Preparing \n",
      "\u001b[1B93a511e9: Preparing \n",
      "\u001b[1B34dc443b: Preparing \n",
      "\u001b[1B711df71e: Preparing \n",
      "\u001b[1B0c6970e5: Preparing \n",
      "\u001b[1Be82df0c2: Preparing \n",
      "\u001b[1B89b11fc2: Preparing \n",
      "\u001b[1Bb7e6614f: Preparing \n",
      "\u001b[1Bc5838665: Preparing \n",
      "\u001b[1B7ea5d26b: Preparing \n",
      "\u001b[1B7acf624e: Preparing \n",
      "\u001b[1Ba0fe4fdd: Preparing \n",
      "\u001b[1B1c46eb92: Preparing \n",
      "\u001b[1B6e800c43: Preparing \n",
      "\u001b[1Bf22d44f3: Preparing \n",
      "\u001b[1B6f329a25: Preparing \n",
      "\u001b[1B7de5faec: Preparing \n",
      "\u001b[1Ba27b0484: Mounted from pjh177787/oxford_scoring_app \u001b[19A\u001b[1K\u001b[K\u001b[21A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[Klatest: digest: sha256:a3173586db425c21be1f7fa176b4fdf0fcae5c5a435dca60672b4b1e24468001 size: 5129\n"
     ]
    }
   ],
   "source": [
    "!sudo docker push {repo}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Flask App Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our Dockerfile and save it to the directory, `flask_app/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing flask_app/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile flask_app/Dockerfile\n",
    "\n",
    "FROM continuumio/miniconda3\n",
    "\n",
    "RUN mkdir /app\n",
    "WORKDIR /app\n",
    "ADD add_images_to_queue.py /app\n",
    "ADD preprocess.py /app\n",
    "ADD postprocess.py /app\n",
    "ADD util.py /app\n",
    "ADD main.py /app\n",
    "ADD constants.py /app\n",
    "\n",
    "RUN conda install -c conda-forge -y ffmpeg\n",
    "RUN pip install azure\n",
    "RUN pip install flask\n",
    "\n",
    "RUN rm /opt/conda/lib/python3.7/site-packages/azure/servicebus/constants.py\n",
    "RUN cp constants.py /opt/conda/lib/python3.7/site-packages/azure/servicebus/\n",
    "\n",
    "CMD [\"python\", \"main.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  26.11kB\n",
      "Step 1/15 : FROM continuumio/miniconda3\n",
      " ---> 6b5cf97566c3\n",
      "Step 2/15 : RUN mkdir /app\n",
      " ---> Using cache\n",
      " ---> 3e41fbdb3278\n",
      "Step 3/15 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> 032cc5cbe3da\n",
      "Step 4/15 : ADD add_images_to_queue.py /app\n",
      " ---> Using cache\n",
      " ---> a7aad3e80c4e\n",
      "Step 5/15 : ADD preprocess.py /app\n",
      " ---> Using cache\n",
      " ---> 88ec5fb7fcf2\n",
      "Step 6/15 : ADD postprocess.py /app\n",
      " ---> Using cache\n",
      " ---> 796d0a2feade\n",
      "Step 7/15 : ADD util.py /app\n",
      " ---> Using cache\n",
      " ---> 842a56dcdc61\n",
      "Step 8/15 : ADD main.py /app\n",
      " ---> Using cache\n",
      " ---> c01786b74db0\n",
      "Step 9/15 : ADD constants.py /app\n",
      " ---> Using cache\n",
      " ---> 768f91f78a6d\n",
      "Step 10/15 : RUN conda install -c conda-forge -y ffmpeg\n",
      " ---> Using cache\n",
      " ---> 063cda8ad60a\n",
      "Step 11/15 : RUN pip install azure\n",
      " ---> Using cache\n",
      " ---> 8657da9773a1\n",
      "Step 12/15 : RUN pip install flask\n",
      " ---> Using cache\n",
      " ---> 9413b1052c11\n",
      "Step 13/15 : RUN rm /opt/conda/lib/python3.7/site-packages/azure/servicebus/constants.py\n",
      " ---> Using cache\n",
      " ---> e1a02d265fd4\n",
      "Step 14/15 : RUN cp constants.py /opt/conda/lib/python3.7/site-packages/azure/servicebus/\n",
      " ---> Using cache\n",
      " ---> f0f85054686e\n",
      "Step 15/15 : CMD [\"python\", \"main.py\"]\n",
      " ---> Using cache\n",
      " ---> 8d863393b785\n",
      "Successfully built 8d863393b785\n",
      "Successfully tagged cambridgefp:latest\n"
     ]
    }
   ],
   "source": [
    "!sudo docker build -t {get_key(env_path, \"FLASK_IMAGE\")} flask_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag and push."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"{}/{}\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"FLASK_IMAGE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker tag {get_key(env_path, \"FLASK_IMAGE\")} {repo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/pjh177787/cambridgefp]\n",
      "\n",
      "\u001b[1B628240c8: Preparing \n",
      "\u001b[1B8b70bd2c: Preparing \n",
      "\u001b[1B5bfaeb6f: Preparing \n",
      "\u001b[1Ba73a5bf7: Preparing \n",
      "\u001b[1B0060ed1e: Preparing \n",
      "\u001b[1Bf4f6db82: Preparing \n",
      "\u001b[1B2767c2e6: Preparing \n",
      "\u001b[1Ba5e2b056: Preparing \n",
      "\u001b[1Bfe3428e9: Preparing \n",
      "\u001b[1B55a10f32: Preparing \n",
      "\u001b[1B18d16c6e: Preparing \n",
      "\u001b[1B66549fba: Preparing \n",
      "\u001b[1Bc65c8dc4: Preparing \n",
      "\u001b[1B2f5d7ee9: Preparing \n",
      "\u001b[1Bb1358a5a: Preparing \n",
      "\u001b[1B1ff9ade6: Preparing \n",
      "\u001b[1B41a8b943: Mounted from pjh177787/oxford_flask_app \u001b[14A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[Klatest: digest: sha256:16c57acc1b0fa990eaa236a0190ba760c8bf4b9112c2ed22274db8888bdd779e size: 3870\n"
     ]
    }
   ],
   "source": [
    "!sudo docker push {repo}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our Flask App and Scoring App deployments on AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to deploy both our aci and aks docker images to the AKS cluster. Since we'll need to set up our gpu and drivers and blobfuse mount point for both deployments, we'll set these up first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_mounts = [\n",
    "#     {\"name\": \"nvidia\", \"mountPath\": \"/usr/local/nvidia\"},\n",
    "    {\"name\": \"blob\", \"mountPath\": get_key(env_path, \"MOUNT_DIR\")},\n",
    "]\n",
    "\n",
    "resources = {\n",
    "#     \"requests\": {\"alpha.kubernetes.io/nvidia-gpu\": 1},\n",
    "#     \"limits\": {\"alpha.kubernetes.io/nvidia-gpu\": 1},\n",
    "}\n",
    "\n",
    "volumes = [\n",
    "#     {\"name\": \"nvidia\", \"hostPath\": {\"path\": \"/usr/local/nvidia\"}},\n",
    "    {\n",
    "        \"name\": \"blob\",\n",
    "        \"flexVolume\": {\n",
    "            \"driver\": \"azure/blobfuse\",\n",
    "            \"readOnly\": False,\n",
    "            \"secretRef\": {\"name\": \"blobfusecreds\"},\n",
    "            \"options\": {\n",
    "                \"container\": get_key(env_path, \"STORAGE_CONTAINER_NAME\"),\n",
    "                \"tmppath\": \"/tmp/blobfuse\",\n",
    "                \"mountoptions\": \"--file-cache-timeout-in-seconds=120 --use-https=true\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "env = [\n",
    "    {\n",
    "        \"name\": \"MOUNT_DIR\", \n",
    "        \"value\": get_key(env_path, \"MOUNT_DIR\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"LB_LIBRARY_PATH\",\n",
    "        \"value\": \"$LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DP_DISABLE_HEALTHCHECKS\", \n",
    "        \"value\": \"xids\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"STORAGE_MODEL_DIR\",\n",
    "        \"value\": get_key(env_path, \"STORAGE_MODEL_DIR\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SUBSCRIPTION_ID\",\n",
    "        \"value\": get_key(env_path, \"SUBSCRIPTION_ID\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"RESOURCE_GROUP\",\n",
    "        \"value\": get_key(env_path, \"RESOURCE_GROUP\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"REGION\",\n",
    "        \"value\": get_key(env_path, \"REGION\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_SHARED_ACCESS_KEY_NAME\",\n",
    "        \"value\": get_key(env_path, \"SB_SHARED_ACCESS_KEY_NAME\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_SHARED_ACCESS_KEY_VALUE\",\n",
    "        \"value\": get_key(env_path, \"SB_SHARED_ACCESS_KEY_VALUE\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_NAMESPACE\",\n",
    "        \"value\": get_key(env_path, \"SB_NAMESPACE\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_QUEUE\", \n",
    "        \"value\": get_key(env_path, \"SB_QUEUE\")\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the aks deployment and save it to a `scoring_app_deployment.json` file using the variables set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_app_deployment_json = {\n",
    "    \"apiVersion\": \"apps/v1beta1\",\n",
    "    \"kind\": \"Deployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"scoring-app\", \n",
    "        \"labels\": {\n",
    "            \"purpose\": \"dequeue_messages_and_apply_style_transfer\"\n",
    "        }\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"replicas\": int(get_key(env_path, \"NODE_COUNT\")) - 1,\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"labels\": {\n",
    "                    \"app\": \"scoring-app\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"scoring-app\",\n",
    "                        \"image\": \"{}/{}:latest\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"SCORING_IMAGE\")),\n",
    "                        \"volumeMounts\": volume_mounts,\n",
    "                        \"resources\": resources,\n",
    "                        \"ports\": [{\n",
    "                            \"containerPort\": 433\n",
    "                        }],\n",
    "                        \"env\": env,\n",
    "                    }\n",
    "                ],\n",
    "                \"volumes\": volumes\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(\"scoring_app_deployment.json\", \"w\") as outfile:\n",
    "    json.dump(scoring_app_deployment_json, outfile, indent=4, sort_keys=True)\n",
    "    outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `scoring_app_deployment.json` we created, create our deployment on AKS. This can take a few minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): error when deleting \"scoring_app_deployment.json\": deployments.apps \"scoring-app\" not found\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f scoring_app_deployment.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/scoring-app created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f scoring_app_deployment.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the flask app deployment and save it to a `flask_app_deployment.json` file using the variables set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flask_app_deployment_json = {\n",
    "    \"apiVersion\": \"apps/v1beta1\",\n",
    "    \"kind\": \"Deployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"flask-app\", \n",
    "        \"labels\": {\n",
    "            \"purpose\": \"pre_and_post_processing_and_queue_images\"\n",
    "        }\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"replicas\": 1,\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"labels\": {\n",
    "                    \"app\": \"flask-app\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"flask-app\",\n",
    "                        \"image\": \"{}/{}:latest\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"FLASK_IMAGE\")),\n",
    "                        \"volumeMounts\": volume_mounts,\n",
    "                        \"resources\": resources,\n",
    "                        \"ports\": [{\n",
    "                            \"containerPort\": 8080\n",
    "                        }],\n",
    "                        \"env\": env,\n",
    "                    }\n",
    "                ],\n",
    "                \"volumes\": volumes\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(\"flask_app_deployment.json\", \"w\") as outfile:\n",
    "    json.dump(flask_app_deployment_json, outfile, indent=4, sort_keys=True)\n",
    "    outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `flask_app_deployment.json` we created, create our flask app deployment on AKS. This can take a few minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): error when deleting \"flask_app_deployment.json\": deployments.apps \"flask-app\" not found\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f flask_app_deployment.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/flask-app created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f flask_app_deployment.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These deployments may take a few minutes. You can inspect the state of the pods by running the command: `kubectl get pods`. When the deployment is done, the results may look as follows:\n",
    "```bash\n",
    "NAME                           READY   STATUS              RESTARTS   AGE\n",
    "flask-app-6db66c97ff-x8rq4     1/1     Running             0          78s\n",
    "scoring-app-846dd6bc79-5nm5b   1/1     Running             0          73s\n",
    "scoring-app-846dd6bc79-6qc6k   1/1     Running             0          73s\n",
    "scoring-app-846dd6bc79-8gtsv   1/1     Running             0          73s\n",
    "scoring-app-846dd6bc79-hjsfc   1/1     Running             0          73s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                          READY   STATUS              RESTARTS   AGE\r\n",
      "aks-ssh-589f4659c5-rdq97      1/1     Running             0          3h9m\r\n",
      "flask-app-6575466bf-lc4g5     1/1     Running             0          3m32s\r\n",
      "scoring-app-94fdf55c8-2k7dk   0/1     ContainerCreating   0          3m43s\r\n",
      "scoring-app-94fdf55c8-6tppl   0/1     ImagePullBackOff    0          3m43s\r\n",
      "scoring-app-94fdf55c8-bnd4j   0/1     ContainerCreating   0          3m43s\r\n",
      "scoring-app-94fdf55c8-g7hlz   0/1     ImagePullBackOff    0          3m43s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (BadRequest): container \"scoring-app\" in pod \"scoring-app-94fdf55c8-g7hlz\" is waiting to start: trying and failing to pull image\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs scoring-app-94fdf55c8-g7hlz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:           aks-ssh-589f4659c5-rdq97\r\n",
      "Namespace:      default\r\n",
      "Priority:       0\r\n",
      "Node:           aks-nodepool1-21996804-4/10.240.0.4\r\n",
      "Start Time:     Wed, 17 Jul 2019 06:33:16 +0000\r\n",
      "Labels:         pod-template-hash=589f4659c5\r\n",
      "                run=aks-ssh\r\n",
      "Annotations:    <none>\r\n",
      "Status:         Running\r\n",
      "IP:             10.244.4.3\r\n",
      "Controlled By:  ReplicaSet/aks-ssh-589f4659c5\r\n",
      "Containers:\r\n",
      "  aks-ssh:\r\n",
      "    Container ID:   docker://7f475f1306f46f41c74510b2e880a34df6d0f1c564a4810ad33dc86792a27177\r\n",
      "    Image:          debian\r\n",
      "    Image ID:       docker-pullable://debian@sha256:903779f30a7ee46937bfb21406f125d5fdace4178074e1cc71c49039ebf7f48f\r\n",
      "    Port:           <none>\r\n",
      "    Host Port:      <none>\r\n",
      "    State:          Running\r\n",
      "      Started:      Wed, 17 Jul 2019 06:33:54 +0000\r\n",
      "    Ready:          True\r\n",
      "    Restart Count:  0\r\n",
      "    Environment:\r\n",
      "      KUBERNETES_PORT_443_TCP_ADDR:  cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "      KUBERNETES_PORT:               tcp://cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_PORT_443_TCP:       tcp://cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_SERVICE_HOST:       cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "    Mounts:\r\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2pfhq (ro)\r\n",
      "Conditions:\r\n",
      "  Type              Status\r\n",
      "  Initialized       True \r\n",
      "  Ready             True \r\n",
      "  ContainersReady   True \r\n",
      "  PodScheduled      True \r\n",
      "Volumes:\r\n",
      "  default-token-2pfhq:\r\n",
      "    Type:        Secret (a volume populated by a Secret)\r\n",
      "    SecretName:  default-token-2pfhq\r\n",
      "    Optional:    false\r\n",
      "QoS Class:       BestEffort\r\n",
      "Node-Selectors:  <none>\r\n",
      "Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\r\n",
      "                 node.kubernetes.io/unreachable:NoExecute for 300s\r\n",
      "Events:          <none>\r\n",
      "\r\n",
      "\r\n",
      "Name:           flask-app-6575466bf-lc4g5\r\n",
      "Namespace:      default\r\n",
      "Priority:       0\r\n",
      "Node:           aks-nodepool1-21996804-1/10.240.0.8\r\n",
      "Start Time:     Wed, 17 Jul 2019 09:39:09 +0000\r\n",
      "Labels:         app=flask-app\r\n",
      "                pod-template-hash=6575466bf\r\n",
      "Annotations:    <none>\r\n",
      "Status:         Running\r\n",
      "IP:             10.244.3.3\r\n",
      "Controlled By:  ReplicaSet/flask-app-6575466bf\r\n",
      "Containers:\r\n",
      "  flask-app:\r\n",
      "    Container ID:   docker://83594cdc3887847f5586b574bf931a017ffef5b9731a79337780af4418ff6831\r\n",
      "    Image:          pjh177787/cambridgefp:latest\r\n",
      "    Image ID:       docker-pullable://pjh177787/cambridgefp@sha256:16c57acc1b0fa990eaa236a0190ba760c8bf4b9112c2ed22274db8888bdd779e\r\n",
      "    Port:           8080/TCP\r\n",
      "    Host Port:      0/TCP\r\n",
      "    State:          Running\r\n",
      "      Started:      Wed, 17 Jul 2019 09:40:27 +0000\r\n",
      "    Ready:          True\r\n",
      "    Restart Count:  0\r\n",
      "    Environment:\r\n",
      "      MOUNT_DIR:                     /data\r\n",
      "      LB_LIBRARY_PATH:               $LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\r\n",
      "      DP_DISABLE_HEALTHCHECKS:       xids\r\n",
      "      STORAGE_MODEL_DIR:             models\r\n",
      "      SUBSCRIPTION_ID:               43f94930-ca31-4ddc-91c2-2f1be4f0e8f3\r\n",
      "      RESOURCE_GROUP:                cambridge\r\n",
      "      REGION:                        chinaeast2\r\n",
      "      SB_SHARED_ACCESS_KEY_NAME:     RootManageSharedAccessKey\r\n",
      "      SB_SHARED_ACCESS_KEY_VALUE:    pxiPuAEazRxwFvX/ekqXrcckWDHEYh9ruJQ5FTdYn5g=\r\n",
      "      SB_NAMESPACE:                  cambridgena\r\n",
      "      SB_QUEUE:                      cambridgequ\r\n",
      "      KUBERNETES_PORT_443_TCP_ADDR:  cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "      KUBERNETES_PORT:               tcp://cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_PORT_443_TCP:       tcp://cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_SERVICE_HOST:       cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "    Mounts:\r\n",
      "      /data from blob (rw)\r\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2pfhq (ro)\r\n",
      "Conditions:\r\n",
      "  Type              Status\r\n",
      "  Initialized       True \r\n",
      "  Ready             True \r\n",
      "  ContainersReady   True \r\n",
      "  PodScheduled      True \r\n",
      "Volumes:\r\n",
      "  blob:\r\n",
      "    Type:       FlexVolume (a generic volume resource that is provisioned/attached using an exec based plugin)\r\n",
      "    Driver:     azure/blobfuse\r\n",
      "    FSType:     \r\n",
      "    SecretRef:  &LocalObjectReference{Name:blobfusecreds,}\r\n",
      "    ReadOnly:   false\r\n",
      "    Options:    map[container:cambridgesc mountoptions:--file-cache-timeout-in-seconds=120 --use-https=true tmppath:/tmp/blobfuse]\r\n",
      "  default-token-2pfhq:\r\n",
      "    Type:        Secret (a volume populated by a Secret)\r\n",
      "    SecretName:  default-token-2pfhq\r\n",
      "    Optional:    false\r\n",
      "QoS Class:       BestEffort\r\n",
      "Node-Selectors:  <none>\r\n",
      "Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\r\n",
      "                 node.kubernetes.io/unreachable:NoExecute for 300s\r\n",
      "Events:\r\n",
      "  Type    Reason     Age   From                               Message\r\n",
      "  ----    ------     ----  ----                               -------\r\n",
      "  Normal  Scheduled  112s  default-scheduler                  Successfully assigned default/flask-app-6575466bf-lc4g5 to aks-nodepool1-21996804-1\r\n",
      "  Normal  Pulling    111s  kubelet, aks-nodepool1-21996804-1  pulling image \"pjh177787/cambridgefp:latest\"\r\n",
      "  Normal  Pulled     55s   kubelet, aks-nodepool1-21996804-1  Successfully pulled image \"pjh177787/cambridgefp:latest\"\r\n",
      "  Normal  Created    34s   kubelet, aks-nodepool1-21996804-1  Created container\r\n",
      "  Normal  Started    34s   kubelet, aks-nodepool1-21996804-1  Started container\r\n",
      "\r\n",
      "\r\n",
      "Name:           scoring-app-94fdf55c8-2k7dk\r\n",
      "Namespace:      default\r\n",
      "Priority:       0\r\n",
      "Node:           aks-nodepool1-21996804-4/10.240.0.4\r\n",
      "Start Time:     Wed, 17 Jul 2019 09:38:58 +0000\r\n",
      "Labels:         app=scoring-app\r\n",
      "                pod-template-hash=94fdf55c8\r\n",
      "Annotations:    <none>\r\n",
      "Status:         Pending\r\n",
      "IP:             \r\n",
      "Controlled By:  ReplicaSet/scoring-app-94fdf55c8\r\n",
      "Containers:\r\n",
      "  scoring-app:\r\n",
      "    Container ID:   \r\n",
      "    Image:          pjh177787/cambridgesp:latest\r\n",
      "    Image ID:       \r\n",
      "    Port:           433/TCP\r\n",
      "    Host Port:      0/TCP\r\n",
      "    State:          Waiting\r\n",
      "      Reason:       ContainerCreating\r\n",
      "    Ready:          False\r\n",
      "    Restart Count:  0\r\n",
      "    Environment:\r\n",
      "      MOUNT_DIR:                     /data\r\n",
      "      LB_LIBRARY_PATH:               $LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\r\n",
      "      DP_DISABLE_HEALTHCHECKS:       xids\r\n",
      "      STORAGE_MODEL_DIR:             models\r\n",
      "      SUBSCRIPTION_ID:               43f94930-ca31-4ddc-91c2-2f1be4f0e8f3\r\n",
      "      RESOURCE_GROUP:                cambridge\r\n",
      "      REGION:                        chinaeast2\r\n",
      "      SB_SHARED_ACCESS_KEY_NAME:     RootManageSharedAccessKey\r\n",
      "      SB_SHARED_ACCESS_KEY_VALUE:    pxiPuAEazRxwFvX/ekqXrcckWDHEYh9ruJQ5FTdYn5g=\r\n",
      "      SB_NAMESPACE:                  cambridgena\r\n",
      "      SB_QUEUE:                      cambridgequ\r\n",
      "      KUBERNETES_PORT_443_TCP_ADDR:  cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "      KUBERNETES_PORT:               tcp://cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_PORT_443_TCP:       tcp://cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_SERVICE_HOST:       cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "    Mounts:\r\n",
      "      /data from blob (rw)\r\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2pfhq (ro)\r\n",
      "Conditions:\r\n",
      "  Type              Status\r\n",
      "  Initialized       True \r\n",
      "  Ready             False \r\n",
      "  ContainersReady   False \r\n",
      "  PodScheduled      True \r\n",
      "Volumes:\r\n",
      "  blob:\r\n",
      "    Type:       FlexVolume (a generic volume resource that is provisioned/attached using an exec based plugin)\r\n",
      "    Driver:     azure/blobfuse\r\n",
      "    FSType:     \r\n",
      "    SecretRef:  &LocalObjectReference{Name:blobfusecreds,}\r\n",
      "    ReadOnly:   false\r\n",
      "    Options:    map[container:cambridgesc mountoptions:--file-cache-timeout-in-seconds=120 --use-https=true tmppath:/tmp/blobfuse]\r\n",
      "  default-token-2pfhq:\r\n",
      "    Type:        Secret (a volume populated by a Secret)\r\n",
      "    SecretName:  default-token-2pfhq\r\n",
      "    Optional:    false\r\n",
      "QoS Class:       BestEffort\r\n",
      "Node-Selectors:  <none>\r\n",
      "Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\r\n",
      "                 node.kubernetes.io/unreachable:NoExecute for 300s\r\n",
      "Events:\r\n",
      "  Type    Reason     Age   From                               Message\r\n",
      "  ----    ------     ----  ----                               -------\r\n",
      "  Normal  Scheduled  2m3s  default-scheduler                  Successfully assigned default/scoring-app-94fdf55c8-2k7dk to aks-nodepool1-21996804-4\r\n",
      "  Normal  Pulling    2m2s  kubelet, aks-nodepool1-21996804-4  pulling image \"pjh177787/cambridgesp:latest\"\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "Name:           scoring-app-94fdf55c8-6tppl\r\n",
      "Namespace:      default\r\n",
      "Priority:       0\r\n",
      "Node:           aks-nodepool1-21996804-3/10.240.0.7\r\n",
      "Start Time:     Wed, 17 Jul 2019 09:38:58 +0000\r\n",
      "Labels:         app=scoring-app\r\n",
      "                pod-template-hash=94fdf55c8\r\n",
      "Annotations:    <none>\r\n",
      "Status:         Pending\r\n",
      "IP:             10.244.1.5\r\n",
      "Controlled By:  ReplicaSet/scoring-app-94fdf55c8\r\n",
      "Containers:\r\n",
      "  scoring-app:\r\n",
      "    Container ID:   \r\n",
      "    Image:          pjh177787/cambridgesp:latest\r\n",
      "    Image ID:       \r\n",
      "    Port:           433/TCP\r\n",
      "    Host Port:      0/TCP\r\n",
      "    State:          Waiting\r\n",
      "      Reason:       ImagePullBackOff\r\n",
      "    Ready:          False\r\n",
      "    Restart Count:  0\r\n",
      "    Environment:\r\n",
      "      MOUNT_DIR:                     /data\r\n",
      "      LB_LIBRARY_PATH:               $LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\r\n",
      "      DP_DISABLE_HEALTHCHECKS:       xids\r\n",
      "      STORAGE_MODEL_DIR:             models\r\n",
      "      SUBSCRIPTION_ID:               43f94930-ca31-4ddc-91c2-2f1be4f0e8f3\r\n",
      "      RESOURCE_GROUP:                cambridge\r\n",
      "      REGION:                        chinaeast2\r\n",
      "      SB_SHARED_ACCESS_KEY_NAME:     RootManageSharedAccessKey\r\n",
      "      SB_SHARED_ACCESS_KEY_VALUE:    pxiPuAEazRxwFvX/ekqXrcckWDHEYh9ruJQ5FTdYn5g=\r\n",
      "      SB_NAMESPACE:                  cambridgena\r\n",
      "      SB_QUEUE:                      cambridgequ\r\n",
      "      KUBERNETES_PORT_443_TCP_ADDR:  cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "      KUBERNETES_PORT:               tcp://cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_PORT_443_TCP:       tcp://cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_SERVICE_HOST:       cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "    Mounts:\r\n",
      "      /data from blob (rw)\r\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2pfhq (ro)\r\n",
      "Conditions:\r\n",
      "  Type              Status\r\n",
      "  Initialized       True \r\n",
      "  Ready             False \r\n",
      "  ContainersReady   False \r\n",
      "  PodScheduled      True \r\n",
      "Volumes:\r\n",
      "  blob:\r\n",
      "    Type:       FlexVolume (a generic volume resource that is provisioned/attached using an exec based plugin)\r\n",
      "    Driver:     azure/blobfuse\r\n",
      "    FSType:     \r\n",
      "    SecretRef:  &LocalObjectReference{Name:blobfusecreds,}\r\n",
      "    ReadOnly:   false\r\n",
      "    Options:    map[container:cambridgesc mountoptions:--file-cache-timeout-in-seconds=120 --use-https=true tmppath:/tmp/blobfuse]\r\n",
      "  default-token-2pfhq:\r\n",
      "    Type:        Secret (a volume populated by a Secret)\r\n",
      "    SecretName:  default-token-2pfhq\r\n",
      "    Optional:    false\r\n",
      "QoS Class:       BestEffort\r\n",
      "Node-Selectors:  <none>\r\n",
      "Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\r\n",
      "                 node.kubernetes.io/unreachable:NoExecute for 300s\r\n",
      "Events:\r\n",
      "  Type     Reason          Age                  From                               Message\r\n",
      "  ----     ------          ----                 ----                               -------\r\n",
      "  Normal   Scheduled       2m3s                 default-scheduler                  Successfully assigned default/scoring-app-94fdf55c8-6tppl to aks-nodepool1-21996804-3\r\n",
      "  Warning  Failed          106s                 kubelet, aks-nodepool1-21996804-3  Failed to pull image \"pjh177787/cambridgesp:latest\": rpc error: code = Unknown desc = error pulling image configuration: Get https://production.cloudflare.docker.com/registry-v2/docker/registry/v2/blobs/sha256/a0/a0ad434be76143b4c3890e9b5ac1a9a65d362c9e849fc0f06a8689b55fafc629/data?verify=1563359344-0TcTKySv5NvBRzOm5XyRTZNmdzQ%3D: net/http: TLS handshake timeout\r\n",
      "  Warning  Failed          106s                 kubelet, aks-nodepool1-21996804-3  Error: ErrImagePull\r\n",
      "  Normal   SandboxChanged  106s                 kubelet, aks-nodepool1-21996804-3  Pod sandbox changed, it will be killed and re-created.\r\n",
      "  Normal   BackOff         104s (x2 over 105s)  kubelet, aks-nodepool1-21996804-3  Back-off pulling image \"pjh177787/cambridgesp:latest\"\r\n",
      "  Warning  Failed          104s (x2 over 105s)  kubelet, aks-nodepool1-21996804-3  Error: ImagePullBackOff\r\n",
      "  Normal   Pulling         91s (x2 over 2m2s)   kubelet, aks-nodepool1-21996804-3  pulling image \"pjh177787/cambridgesp:latest\"\r\n",
      "\r\n",
      "\r\n",
      "Name:           scoring-app-94fdf55c8-bnd4j\r\n",
      "Namespace:      default\r\n",
      "Priority:       0\r\n",
      "Node:           aks-nodepool1-21996804-0/10.240.0.5\r\n",
      "Start Time:     Wed, 17 Jul 2019 09:38:58 +0000\r\n",
      "Labels:         app=scoring-app\r\n",
      "                pod-template-hash=94fdf55c8\r\n",
      "Annotations:    <none>\r\n",
      "Status:         Pending\r\n",
      "IP:             \r\n",
      "Controlled By:  ReplicaSet/scoring-app-94fdf55c8\r\n",
      "Containers:\r\n",
      "  scoring-app:\r\n",
      "    Container ID:   \r\n",
      "    Image:          pjh177787/cambridgesp:latest\r\n",
      "    Image ID:       \r\n",
      "    Port:           433/TCP\r\n",
      "    Host Port:      0/TCP\r\n",
      "    State:          Waiting\r\n",
      "      Reason:       ContainerCreating\r\n",
      "    Ready:          False\r\n",
      "    Restart Count:  0\r\n",
      "    Environment:\r\n",
      "      MOUNT_DIR:                     /data\r\n",
      "      LB_LIBRARY_PATH:               $LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\r\n",
      "      DP_DISABLE_HEALTHCHECKS:       xids\r\n",
      "      STORAGE_MODEL_DIR:             models\r\n",
      "      SUBSCRIPTION_ID:               43f94930-ca31-4ddc-91c2-2f1be4f0e8f3\r\n",
      "      RESOURCE_GROUP:                cambridge\r\n",
      "      REGION:                        chinaeast2\r\n",
      "      SB_SHARED_ACCESS_KEY_NAME:     RootManageSharedAccessKey\r\n",
      "      SB_SHARED_ACCESS_KEY_VALUE:    pxiPuAEazRxwFvX/ekqXrcckWDHEYh9ruJQ5FTdYn5g=\r\n",
      "      SB_NAMESPACE:                  cambridgena\r\n",
      "      SB_QUEUE:                      cambridgequ\r\n",
      "      KUBERNETES_PORT_443_TCP_ADDR:  cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "      KUBERNETES_PORT:               tcp://cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_PORT_443_TCP:       tcp://cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_SERVICE_HOST:       cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "    Mounts:\r\n",
      "      /data from blob (rw)\r\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2pfhq (ro)\r\n",
      "Conditions:\r\n",
      "  Type              Status\r\n",
      "  Initialized       True \r\n",
      "  Ready             False \r\n",
      "  ContainersReady   False \r\n",
      "  PodScheduled      True \r\n",
      "Volumes:\r\n",
      "  blob:\r\n",
      "    Type:       FlexVolume (a generic volume resource that is provisioned/attached using an exec based plugin)\r\n",
      "    Driver:     azure/blobfuse\r\n",
      "    FSType:     \r\n",
      "    SecretRef:  &LocalObjectReference{Name:blobfusecreds,}\r\n",
      "    ReadOnly:   false\r\n",
      "    Options:    map[container:cambridgesc mountoptions:--file-cache-timeout-in-seconds=120 --use-https=true tmppath:/tmp/blobfuse]\r\n",
      "  default-token-2pfhq:\r\n",
      "    Type:        Secret (a volume populated by a Secret)\r\n",
      "    SecretName:  default-token-2pfhq\r\n",
      "    Optional:    false\r\n",
      "QoS Class:       BestEffort\r\n",
      "Node-Selectors:  <none>\r\n",
      "Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\r\n",
      "                 node.kubernetes.io/unreachable:NoExecute for 300s\r\n",
      "Events:\r\n",
      "  Type    Reason     Age   From                               Message\r\n",
      "  ----    ------     ----  ----                               -------\r\n",
      "  Normal  Scheduled  2m3s  default-scheduler                  Successfully assigned default/scoring-app-94fdf55c8-bnd4j to aks-nodepool1-21996804-0\r\n",
      "  Normal  Pulling    2m2s  kubelet, aks-nodepool1-21996804-0  pulling image \"pjh177787/cambridgesp:latest\"\r\n",
      "\r\n",
      "\r\n",
      "Name:           scoring-app-94fdf55c8-g7hlz\r\n",
      "Namespace:      default\r\n",
      "Priority:       0\r\n",
      "Node:           aks-nodepool1-21996804-2/10.240.0.6\r\n",
      "Start Time:     Wed, 17 Jul 2019 09:38:58 +0000\r\n",
      "Labels:         app=scoring-app\r\n",
      "                pod-template-hash=94fdf55c8\r\n",
      "Annotations:    <none>\r\n",
      "Status:         Pending\r\n",
      "IP:             \r\n",
      "Controlled By:  ReplicaSet/scoring-app-94fdf55c8\r\n",
      "Containers:\r\n",
      "  scoring-app:\r\n",
      "    Container ID:   \r\n",
      "    Image:          pjh177787/cambridgesp:latest\r\n",
      "    Image ID:       \r\n",
      "    Port:           433/TCP\r\n",
      "    Host Port:      0/TCP\r\n",
      "    State:          Waiting\r\n",
      "      Reason:       ContainerCreating\r\n",
      "    Ready:          False\r\n",
      "    Restart Count:  0\r\n",
      "    Environment:\r\n",
      "      MOUNT_DIR:                     /data\r\n",
      "      LB_LIBRARY_PATH:               $LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\r\n",
      "      DP_DISABLE_HEALTHCHECKS:       xids\r\n",
      "      STORAGE_MODEL_DIR:             models\r\n",
      "      SUBSCRIPTION_ID:               43f94930-ca31-4ddc-91c2-2f1be4f0e8f3\r\n",
      "      RESOURCE_GROUP:                cambridge\r\n",
      "      REGION:                        chinaeast2\r\n",
      "      SB_SHARED_ACCESS_KEY_NAME:     RootManageSharedAccessKey\r\n",
      "      SB_SHARED_ACCESS_KEY_VALUE:    pxiPuAEazRxwFvX/ekqXrcckWDHEYh9ruJQ5FTdYn5g=\r\n",
      "      SB_NAMESPACE:                  cambridgena\r\n",
      "      SB_QUEUE:                      cambridgequ\r\n",
      "      KUBERNETES_PORT_443_TCP_ADDR:  cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "      KUBERNETES_PORT:               tcp://cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_PORT_443_TCP:       tcp://cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_SERVICE_HOST:       cambridgec-cambridge-43f949-773a2dc2.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "    Mounts:\r\n",
      "      /data from blob (rw)\r\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2pfhq (ro)\r\n",
      "Conditions:\r\n",
      "  Type              Status\r\n",
      "  Initialized       True \r\n",
      "  Ready             False \r\n",
      "  ContainersReady   False \r\n",
      "  PodScheduled      True \r\n",
      "Volumes:\r\n",
      "  blob:\r\n",
      "    Type:       FlexVolume (a generic volume resource that is provisioned/attached using an exec based plugin)\r\n",
      "    Driver:     azure/blobfuse\r\n",
      "    FSType:     \r\n",
      "    SecretRef:  &LocalObjectReference{Name:blobfusecreds,}\r\n",
      "    ReadOnly:   false\r\n",
      "    Options:    map[container:cambridgesc mountoptions:--file-cache-timeout-in-seconds=120 --use-https=true tmppath:/tmp/blobfuse]\r\n",
      "  default-token-2pfhq:\r\n",
      "    Type:        Secret (a volume populated by a Secret)\r\n",
      "    SecretName:  default-token-2pfhq\r\n",
      "    Optional:    false\r\n",
      "QoS Class:       BestEffort\r\n",
      "Node-Selectors:  <none>\r\n",
      "Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\r\n",
      "                 node.kubernetes.io/unreachable:NoExecute for 300s\r\n",
      "Events:\r\n",
      "  Type    Reason     Age   From                               Message\r\n",
      "  ----    ------     ----  ----                               -------\r\n",
      "  Normal  Scheduled  2m3s  default-scheduler                  Successfully assigned default/scoring-app-94fdf55c8-g7hlz to aks-nodepool1-21996804-2\r\n",
      "  Normal  Pulling    2m2s  kubelet, aks-nodepool1-21996804-2  pulling image \"pjh177787/cambridgesp:latest\"\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expose the flask-app in the kubernetes cluster. This will open a public endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl expose deployment flask-app --type=\"LoadBalancer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `!watch kubectl get services` and wait until the external ip goes from pending to being realized. It can take some time.\n",
    "\n",
    "NOTE: If the following command is run without the external ip being realized, an error will be thrown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_ip = !kubectl get services -o=jsonpath={.items[*].status.loadBalancer.ingress[0].ip}\n",
    "external_ip = external_ip[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'll use the `external_ip` later on, save it to the dot-env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "strip_out"
    ]
   },
   "outputs": [],
   "source": [
    "set_key(env_path, \"AKS_EXTERNAL_IP\", external_ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that the deployment works end-to-end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the name of the new test video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_video_name = \"aks_test_orangutan.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a copy the old `orangutan.mp4` video but named with the `<new_video_name>`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp data/orangutan.mp4 data/{new_video_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `curl` to hit the endpoint of the kubernetes cluster we just deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl {external_ip}\":8080/process?video_name=\"{new_video_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect your kubernetes cluster to see that the process is running. You can use the commands below to do so. Alternatively, you can also inspect the blob storage container to see that the images are being created.\n",
    "\n",
    "When the video completes, you can play the video file directly from your mounted blob container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\"data/aks_test_orangutan/aks_test_orangutan_processed.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Kubectl usage\n",
    "You can use kubectl to perform basic monitoring. Use the following commands:\n",
    "```bash\n",
    "# monitor pods\n",
    "!kubectl get pods\n",
    "\n",
    "# print logs from a pod (<pod-name> can be found when calling 'get pods')\n",
    "!kubectl logs <pod-name>\n",
    "\n",
    "# check all services running on the cluster\n",
    "!kubectl get services\n",
    "\n",
    "# delete a service\n",
    "!kubectl delete services <service-name>\n",
    "\n",
    "# delete a deployment\n",
    "!kubectl delete -f scoring_app_deployment.json\n",
    "!kubectl delete -f flask_app_deployment.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor in kubernetes dashboard\n",
    "You can use the Kubernetes dashboard to monitor the cluster using the following commands:\n",
    "\n",
    "```bash\n",
    "# use the kube_dashboard_access.yaml to create a deployment\n",
    "!kubectl create -f kube_dashboard_access.yaml\n",
    "\n",
    "# use this command to browse\n",
    "!az aks browse -n {get_key(env_path, \"AKS_CLUSTER\")} -g {get_key(env_path, \"RESOURCE_GROUP\")}\n",
    "```\n",
    "\n",
    "If you're not able to access the dashboard, follow the instructions [here](https://blog.tekspace.io/kubernetes-dashboard-remote-access/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional commands for AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale your AKS cluster:\n",
    "\n",
    "```bash \n",
    "!az aks scale \\\n",
    "    --name {get_key(env_path, \"AKS_CLUSTER\")} \\\n",
    "    --resource-group {get_key(env_path, \"RESOURCE_GROUP\")} \\\n",
    "    --node-count 10\n",
    "```\n",
    "\n",
    "Scale your deployment:\n",
    "```bash\n",
    "!kubectl scale deployment.apps/aks-app --replicas=10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to the next [notebook](/notebooks/05_deploy_logic_app.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bc_aks] *",
   "language": "python",
   "name": "conda-env-bc_aks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
